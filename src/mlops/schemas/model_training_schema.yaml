random_search:
  n_iter: 5
  cv: 5
  fbeta: 2
  n_jobs: -1
  verbose: 0

threshold_tuning:
  fbeta: 2
  response_method: "predict_proba"
  thresholds: 100
  cv: 5
  n_jobs: -1

feature_selection:
  method: "SelectKBest"
  param_distributions:
    k: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]

models:
  logistic_regression:
    param_distributions:
      penalty: ["l2"]
      C: [0.001, 0.01, 0.1, 1, 10, 100]
      solver: ["liblinear", "saga", "lbfgs", "newton-cg"]
      max_iter: [200, 300, 500]
      class_weight: [null, "balanced"]

  random_forest:
    param_distributions:
      n_estimators: [50, 100, 200, 250]
      max_depth: [null, 5, 10, 20, 50]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]
      max_features: ["sqrt", "log2"]
      bootstrap: [True, False]
      criterion: ["gini", "entropy"]
      class_weight: [null, "balanced", "balanced_subsample"]

  xgboost:
    param_distributions:
      n_estimators: [50, 100, 200, 250]
      max_depth: [3, 5, 7, 10]
      learning_rate: [0.01, 0.05, 0.1, 0.2]
      subsample: [0.5, 0.7, 1.0]
      colsample_bytree: [0.5, 0.7, 1.0]
      gamma: [0, 0.1, 0.3, 0.5]
      reg_alpha: [0, 0.1, 0.5, 1]
      reg_lambda: [1, 1.5, 2]
      scale_pos_weight: [1, 5, 10]
      min_child_weight: [1, 3, 5]
